{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 23:56:24.327918: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-19 23:56:24.396424: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-19 23:56:24.396491: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-19 23:56:24.398952: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-19 23:56:24.410064: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-19 23:56:25.854065: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i will  run\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (56,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 106\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_test \u001b[38;5;129;01min\u001b[39;00m X_test:\n\u001b[1;32m    104\u001b[0m     X_test_avg\u001b[38;5;241m.\u001b[39mappend(textclassifier\u001b[38;5;241m.\u001b[39msentence_to_feature_vectors_avg(x_test))\n\u001b[0;32m--> 106\u001b[0m X_test_avg \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_avg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m Y_train_one_hot \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mto_categorical(Y_train, num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m    110\u001b[0m Y_test_one_hot \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mto_categorical(Y_test, num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (56,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class EmojiTextClassifier:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "\n",
    "    def load_dataset(self, dataset_path):\n",
    "        df = pd.read_csv(dataset_path)\n",
    "        X = np.array(df[\"sentence\"])\n",
    "        Y = np.array(df[\"label\"], dtype = np.float64)\n",
    "        return X, Y\n",
    "    \n",
    "    def load_feature_vector(self,vector_file):\n",
    "        self.word_vectors = {}\n",
    "\n",
    "        for line in vector_file:\n",
    "            line = line.strip().split(\" \")\n",
    "            word = line[0]\n",
    "            vector = np.array(line[1:], dtype = np.float64)\n",
    "            self.word_vectors[word] = vector\n",
    "\n",
    "    def sentence_to_feature_vectors_avg(self, sentence):\n",
    "        \n",
    "        try:\n",
    "            sentence = sentence.lower()\n",
    "            words = sentence.strip().split(\" \")\n",
    "            sum_vectors = np.zeros((50, ))\n",
    "            for word in words:\n",
    "                sum_vectors += self.word_vectors[word]\n",
    "\n",
    "            self.avg_vector = sum_vectors / len(words)\n",
    "\n",
    "            return self.avg_vector\n",
    "        except:\n",
    "            print(sentence) \n",
    "\n",
    "\n",
    "\n",
    "    def load_model(self):\n",
    "        self.model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(5, \n",
    "                                  input_shape = (50,),\n",
    "                                  activation = \"softmax\")\n",
    "        ])\n",
    "\n",
    "        self.model.compile(\n",
    "            tf.keras.optimizers.Adam(),\n",
    "            loss = \"categorical_crossentropy\",\n",
    "            metrics = [\"accuracy\"]\n",
    "        )\n",
    "\n",
    "\n",
    "    def train(self, X_train, Y_train):\n",
    "        self.model.fit(X_train, Y_train, epochs = 250)\n",
    "\n",
    "    def test(self, X_test, Y_test):\n",
    "        self.model.evaluate(X_test, Y_test)    \n",
    "\n",
    "    def label_to_emoji(self, label):\n",
    "        emojies = [\"‚ù§Ô∏è\",\"‚öΩÔ∏è\",\"üòÑ\",\"üòî\",\"üçΩ\"]\n",
    "        return emojies[label]\n",
    "    \n",
    "\n",
    "    def inference(self, test_sentence):\n",
    "        test_sentence  = np.array([test_sentence])\n",
    "        result = self.model.predict(test_sentence)\n",
    "        y_pred = np.argmax(result)\n",
    "        label = self.label_to_emoji(y_pred)\n",
    "\n",
    "        return label\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    train_dataset = \"dataset/train.csv\"\n",
    "    test_dataset= \"dataset/test.csv\"\n",
    "    vector_file = open(\"glov.6B/glove.6B.50d.txt\", encoding = \"utf-8\")\n",
    "\n",
    "    X_train_avg = []\n",
    "    X_test_avg = []\n",
    "\n",
    "    textclassifier = EmojiTextClassifier()\n",
    "    X_train, Y_train = textclassifier.load_dataset(train_dataset)\n",
    "    X_test, Y_test = textclassifier.load_dataset(test_dataset)\n",
    "\n",
    "    textclassifier.load_feature_vector(vector_file)\n",
    "\n",
    "    for x_train in X_train:\n",
    "        X_train_avg.append(textclassifier.sentence_to_feature_vectors_avg(x_train))\n",
    "        \n",
    "    X_train_avg = np.array(X_train_avg)\n",
    "\n",
    "\n",
    "    for x_test in X_test:\n",
    "        X_test_avg.append(textclassifier.sentence_to_feature_vectors_avg(x_test))\n",
    "\n",
    "    X_test_avg = np.array(X_test_avg)\n",
    "\n",
    "    \n",
    "    Y_train_one_hot = tf.keras.utils.to_categorical(Y_train, num_classes = 5)\n",
    "    Y_test_one_hot = tf.keras.utils.to_categorical(Y_test, num_classes = 5)\n",
    "\n",
    "    textclassifier.load_model()\n",
    "\n",
    "    textclassifier.train(X_train_avg, Y_train_one_hot)\n",
    "    textclassifier.test(X_test_avg, Y_test_one_hot)\n",
    "\n",
    "\n",
    "    mysentense = textclassifier.sentence_to_feature_vectors_avg(\"I like pizza\")\n",
    "    result = textclassifier.inference(mysentense)\n",
    "    print(result)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
